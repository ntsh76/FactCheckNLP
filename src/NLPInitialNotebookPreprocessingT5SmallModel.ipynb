{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118f4d3a",
   "metadata": {},
   "source": [
    "#### Install libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8989a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "#!pip install nltk\n",
    "#!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206076cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install tensorflow\n",
    "\n",
    "#!pip install transformers\n",
    "#!pip install evaluate\n",
    "#!pip install datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18a112e",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5f1563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Hugging face imports\n",
    "from datasets import load_dataset\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import create_optimizer\n",
    "import evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cbcbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should point to FactCheckNLPApp/\n",
    "BASE_PATH = '../'\n",
    "\n",
    "train_path = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/train.tsv'\n",
    "dev_path = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/dev.tsv'\n",
    "test_path = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/test.tsv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207646d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Download data\n",
    "\n",
    "- This uses data from https://github.com/neemakot/Health-Fact-Checking.\n",
    "- First clone this repo in your local workspace. \n",
    "- Then run download_data script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !../Health-Fact-Checking/src/download_data.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193425ca",
   "metadata": {},
   "source": [
    "#### Preprocess data and select topk sentences from main text\n",
    "\n",
    "- This can take a few hours on a single GPU \n",
    "- Skip this step and download files directly if you don't want to change pre-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c42ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fact_check_nlp.preprocessing import select_evidence_sentences_based_on_cosine_similarity, \\\n",
    "create_claim_sentence_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe4d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_claim_sentence_pair(train_path, \n",
    "                           output_path=train_path.replace('train.tsv', 'train_claim_sentence_pair.csv'))\n",
    "\n",
    "create_claim_sentence_pair(dev_path, \n",
    "                           output_path=dev_path.replace('dev.tsv', 'dev_claim_sentence_pair.csv'))\n",
    "\n",
    "create_claim_sentence_pair(test_path, \n",
    "                           output_path=test_path.replace('test.tsv', 'test_claim_sentence_pair.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c99c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dcb7692",
   "metadata": {},
   "source": [
    "#### Select top_k based on cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbd7034",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "select_evidence_sentences_based_on_cosine_similarity(train_path, k=5, \n",
    "                                output_path=train_path.replace('train.tsv', 'formatted_train_most_similar.csv')\n",
    "                               )\n",
    "\n",
    "select_evidence_sentences_based_on_cosine_similarity(dev_path, k=5, \n",
    "                                output_path=dev_path.replace('dev.tsv', 'formatted_dev_most_similar.csv')\n",
    "                               )\n",
    "\n",
    "select_evidence_sentences_based_on_cosine_similarity(test_path, k=5, \n",
    "                                output_path=test_path.replace('test.tsv', 'formatted_test_most_similar.csv')\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1546e22f",
   "metadata": {},
   "source": [
    "### What does sentence transformer do ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf380df5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentence_transformer_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "    sentence_transformer_model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9acd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "claim = \"Earth is flat.\"\n",
    "\n",
    "lst = [       \n",
    "       \"The earth is round.\",\n",
    "       \"Earth is not flat.\",\n",
    "       \"Earth is a good planet.\",\n",
    "       \"Earth is mostly round.\" \n",
    "      ]\n",
    "\n",
    "text = \" \".join(lst)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fae0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = lst\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "embeddings = model.encode(lst)\n",
    "print(embeddings)\n",
    "\n",
    "claim_vec = model.encode(claim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b0f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_emb = {}\n",
    "for s, e in zip(sentences, embeddings):\n",
    "    new_emb[s] = np.linalg.norm(cosine_similarity([claim_embedding, e]))\n",
    "    \n",
    "new_emb    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a870ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580032e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "k = 3\n",
    "\n",
    "sentences = [sentence for sentence in sent_tokenize(text)]\n",
    "\n",
    "sentence_embeddings = sentence_transformer_model.encode(sentences)\n",
    "claim_embedding = sentence_transformer_model.encode(claim)\n",
    "\n",
    "sentence_embeddings = sentence_embeddings\n",
    "cosine_similarity_emb = {}\n",
    "\n",
    "for sentence, embedding in zip(sentences, sentence_embeddings):\n",
    "    cosine_similarity_emb[sentence] = np.linalg.norm(cosine_similarity(\n",
    "        [claim_embedding, embedding]))\n",
    "    top_k = dict(sorted(cosine_similarity_emb.items(),\n",
    "                            key=itemgetter(1), reverse=True)[:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9fd088",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04be4a2",
   "metadata": {},
   "source": [
    "### Section 1 - Create Dataset with all facts and only True/False labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a115122b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This cell basically drops any missing rows with missing data. Filters only to Health records and True/False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb377ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/formatted_test.csv' \n",
    "df = pd.read_csv(test_file)\n",
    "df['subjects'] = df['subjects'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc513ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/formatted_health_only_train_most_similar.csv' \n",
    "val_file = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/formatted_health_only_dev_most_similar.csv' \n",
    "test_file = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/formatted_health_only_test_most_similar.csv' \n",
    "\n",
    "def filter_df(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df.dropna(how='any', inplace=True)\n",
    "    # print(df.columns)\n",
    "    df['subjects'] = df['subjects'].str.lower()\n",
    "    # df = df[(df['subjects'].str.contains('health'))]\n",
    "    df = df[(df['label'].isin(['true', 'false', 'True', 'False']))]\n",
    "    \n",
    "    df.to_csv(file.replace('formatted', 'formatted_health'), index=False)\n",
    "    print(len(df))\n",
    "    return df\n",
    "\n",
    "df = filter_df(train_file)\n",
    "df = filter_df(val_file)\n",
    "df = filter_df(test_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f0eed",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf298a08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_path = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/formatted_health_health_only_train_most_similar.csv'\n",
    "dev_path = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/formatted_health_health_only_dev_most_similar.csv'\n",
    "test_path = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/formatted_health_health_only_test_most_similar.csv'\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=[train_path])\n",
    "val_dataset = load_dataset(\"csv\", data_files=[dev_path])\n",
    "test_dataset = load_dataset(\"csv\", data_files=[test_path])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea57b9",
   "metadata": {},
   "source": [
    "### Section 2 Train summary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04be9236",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_MODEL_NAME = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db7f24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_tokenizer = GPT2Tokenizer.from_pretrained(SUMMARY_MODEL_NAME)\n",
    "summary_model = GPT2PreTrainedModel.from_pretrained(SUMMARY_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52efa056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import GPT2Tokenizer, GPT2PreTrainedModel, GPT2ForSequenceClassification\n",
    "\n",
    "train_path = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/formatted_train_most_similar.csv'\n",
    "dev_path = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/formatted_dev_most_similar.csv'\n",
    "test_path = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/formatted_test_most_similar.csv'\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=[train_path])\n",
    "val_dataset = load_dataset(\"csv\", data_files=[dev_path])\n",
    "test_dataset = load_dataset(\"csv\", data_files=[test_path])\n",
    "\n",
    "\n",
    "SUMMARY_MODEL_NAME = \"t5-small\"\n",
    "\n",
    "summary_tokenizer = AutoTokenizer.from_pretrained(SUMMARY_MODEL_NAME)\n",
    "summary_model = AutoModelForSeq2SeqLM.from_pretrained(SUMMARY_MODEL_NAME)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=summary_tokenizer, model=summary_model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc918eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_function_summary(examples):\n",
    "    prefix = \"summarize: \"\n",
    "    inputs = [prefix + doc for doc in examples[\"top_k\"]]\n",
    "    model_inputs = summary_tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = summary_tokenizer(text_target=examples[\"explanation\"], \n",
    "                               max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "tokenized_train_sum = dataset.shuffle(seed=42).remove_columns([\"label\", \"subjects\"]).map(preprocess_function_summary, batched=True)\n",
    "tokenized_val_sum = val_dataset.shuffle(seed=42).remove_columns([\"label\", \"subjects\"]).map(preprocess_function_summary, batched=True)\n",
    "tokenized_test_sum = test_dataset.shuffle(seed=42).remove_columns([\"label\", \"subjects\"]).map(preprocess_function_summary, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f0c56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics_summary(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = summary_tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, summary_tokenizer.pad_token_id)\n",
    "    decoded_labels = summary_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != summary_tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"health_summary_model_true_false_{SUMMARY_MODEL_NAME}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    # fp16=True,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=summary_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_sum[\"train\"], #.select(list(np.arange(0, 100))),\n",
    "    eval_dataset=tokenized_val_sum[\"train\"], #.select(list(np.arange(0, 100))),\n",
    "    tokenizer=summary_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics_summary\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2a5f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = trainer.predict(tokenized_test_sum[\"train\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50720ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f211bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = preds.label_ids[0]\n",
    "lbl = np.where(lbl != -100, lbl, tokenizer.pad_token_id)\n",
    "summary_tokenizer.batch_decode(lbl, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc98978",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenized_train_sum['train'][1]['top_k']\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bc82c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = tokenized_train_sum['train'][1]['explanation']\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113929b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge.compute(predictions=preds, references=label, use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcece4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=summary_model, tokenizer=summary_tokenizer, max_length=90)\n",
    "\n",
    "for i in range(0, len(tokenized_test_sum['train'])):\n",
    "    text = tokenized_test_sum['train'][i]['top_k']\n",
    "    label = [tokenized_test_sum['train'][i]['explanation']]\n",
    "    preds = [summarizer(text)[0]['summary_text']]\n",
    "    metrics = rouge.compute(predictions=preds, references=label, use_stemmer=True)\n",
    "    if metrics['rouge1'] > 0.50 or metrics['rouge2'] > 0.40 or metrics['rougeL'] > 0.35:\n",
    "        print(metrics)\n",
    "        print(text)\n",
    "        print(label)\n",
    "        print(preds)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb6c8f1",
   "metadata": {},
   "source": [
    "### Section 3 -Train model for Predicting if a Claim is True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a2764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "id2label = {0: \"true\", 1: \"false\", 1: \"mixture\", 1: \"unproven\"}\n",
    "label2id = {\"true\": 0, \"false\": 1, \"mixture\": 1, \"unproven\": 1}\n",
    "\n",
    "\n",
    "id2label = {0: \"True\", 1: \"False\", 1: \"mixture\", 1: \"unproven\",\n",
    "            0: \"true\", 1: \"false\", 1: \"mixture\", 1: \"unproven\"\n",
    "           }\n",
    "label2id = {\"True\": 0, \"False\": 1, \"mixture\": 1, \"unproven\": 1,\n",
    "           \"true\": 0, \"false\": 1, \"mixture\": 1, \"unproven\": 1\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933dc82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dfc7ef",
   "metadata": {},
   "source": [
    "#### Load Pre-trained Model & Traing it only on Claim texts just to check if everything works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba51cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenized_train[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4541442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"bert-base-cased\"\n",
    "\n",
    "#model_ckpt = \"allenai/scibert_scivocab_uncased\"\n",
    "\n",
    "def preprocess_claim(examples):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "    inputs = tokenizer(examples[\"claim\"], examples[\"top_k\"], truncation=\"only_second\")\n",
    "    \n",
    "    converted_lbls = []\n",
    "    for val in examples['label']:\n",
    "        converted_lbls.append([label2id[str(val)]])\n",
    "\n",
    "    inputs['label'] = converted_lbls\n",
    "    return inputs\n",
    "\n",
    "tokenized_train = dataset.shuffle(seed=42).map(preprocess_claim, batched=True, \n",
    "                              remove_columns=dataset[\"train\"].column_names)\n",
    "tokenized_val = val_dataset.shuffle(seed=42).map(preprocess_claim, batched=True, \n",
    "                                remove_columns=val_dataset[\"train\"].column_names)\n",
    "tokenized_test = test_dataset.shuffle(seed=42).map(preprocess_claim, batched=True, \n",
    "                                  remove_columns=test_dataset[\"train\"].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7c0a05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "from transformers import default_data_collator\n",
    "from torch import nn\n",
    "\n",
    "mps_device = torch.device(\"mps\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt)\n",
    "model\n",
    "\n",
    "# Define training parameters\n",
    "batch_size = 16\n",
    "args = TrainingArguments(\n",
    "    f\"bert-base-cased-healthonly-true-false\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=1, # Set num_train_epochs to 1 as test\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        \n",
    "        # compute custom loss\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.15, 0.85]))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_train[\"train\"], #.select(list(np.arange(1, 1000))),\n",
    "    eval_dataset=tokenized_val[\"train\"], #.select(list(np.arange(1, 100))),\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "preds = trainer.predict(tokenized_test[\"train\"])\n",
    "\n",
    "print(preds.predictions.shape, preds.label_ids.shape)\n",
    "preds.predictions[0]\n",
    "\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "pred_lbl = np.argmax(preds.predictions, axis=-1)\n",
    "\n",
    "metric.compute(predictions=pred_lbl, references=preds.label_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebb5387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(preds.label_ids, pred_lbl, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a42f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb22935",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd5ab69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "claim = \"Being inactive improves heart health.\"\n",
    "\n",
    "top_k = \"There is no evidence that being sedentary improves heart health. This claim is totally baseless. In face being inactive can serious issues as we age.\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "inputs = tokenizer(claim, top_k, truncation=\"only_second\")\n",
    "\n",
    "inputs['label'] = [1]\n",
    "\n",
    "trainer.predict([inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255743ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
