{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b54629",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_MAX_LENGTH = 256\n",
    "PREDICTION_MAX_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02012e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import evaluate \n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "    \n",
    "device = mps_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b899c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = './'\n",
    "train_path = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/formatted_train_most_similar.csv'\n",
    "dev_path = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/formatted_dev_most_similar.csv'\n",
    "test_path = f'{BASE_PATH}Health-Fact-Checking/data/PUBHEALTH/formatted_test_most_similar.csv'\n",
    "FEATURES = ['claim','top_k', 'label']\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=[train_path])\n",
    "val_dataset = load_dataset(\"csv\", data_files=[dev_path])\n",
    "test_dataset = load_dataset(\"csv\", data_files=[test_path])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaaad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/pegasus-xsum\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee5b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "SUMMARY_MODEL_NAME = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_summary(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = summary_tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, summary_tokenizer.pad_token_id)\n",
    "    decoded_labels = summary_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != summary_tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134df048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "summary_tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "summary_model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=summary_tokenizer, \n",
    "                                       model=summary_model)\n",
    "\n",
    "def preprocess_function_summary(examples):\n",
    "    prefix = \"summarize: \"\n",
    "    inputs = [prefix + doc for doc in examples[\"top_k\"]]\n",
    "    # max_length=512, \n",
    "    model_inputs = summary_tokenizer(inputs, max_length=INPUT_MAX_LENGTH, \n",
    "                                     truncation=True, padding=True)\n",
    "    \n",
    "    # max_length=64, \n",
    "    labels = summary_tokenizer(text_target=examples[\"explanation\"], \n",
    "                               max_new_tokens=PREDICTION_MAX_LENGTH, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "\n",
    "tokenized_train_sum = dataset.shuffle(seed=42).remove_columns([\"label\", \"subjects\"]).map(preprocess_function_summary, batched=True)\n",
    "tokenized_val_sum = val_dataset.shuffle(seed=42).remove_columns([\"label\", \"subjects\"]).map(preprocess_function_summary, batched=True)\n",
    "tokenized_test_sum = test_dataset.shuffle(seed=42).remove_columns([\"label\", \"subjects\"]).map(preprocess_function_summary, batched=True)\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"health_summary_model_true_false_{SUMMARY_MODEL_NAME}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    # fp16=True,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=summary_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_sum[\"train\"], #.select(list(np.arange(0, 100))),\n",
    "    eval_dataset=tokenized_val_sum[\"train\"], #.select(list(np.arange(0, 100))),\n",
    "    tokenizer=summary_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics_summary\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736e788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = f'/tmp/explanation-generation-peagusus-{INPUT_MAX_LENGTH}-{PREDICTION_MAX_LENGTH}'\n",
    "# trainer.save_model(save_path)\n",
    "# print(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8e140a",
   "metadata": {},
   "source": [
    "### Generate ROUGE scores on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b03a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = trainer.predict(tokenized_test_sum[\"train\"])\n",
    "preds.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8dc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
    "\n",
    "tokenizer = PegasusTokenizer.from_pretrained(save_path)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test_sum[\"train\"][i]['top_k']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa65bff9",
   "metadata": {},
   "source": [
    "### Apply decoding top_k and top_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190af612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "pred_texts =[]\n",
    "label_texts = []\n",
    "for i in range(len(tokenized_test_sum[\"train\"])):\n",
    "    print(i)\n",
    "    input_text = tokenized_test_sum[\"train\"][i]['top_k']\n",
    "    label_text = tokenized_test_sum[\"train\"][i][\"explanation\"]\n",
    "    \n",
    "    inputs = tokenizer(input_text, truncation=True, return_tensors=\"pt\").input_ids\n",
    "    outputs = model.generate(inputs,\n",
    "                             do_sample=True, \n",
    "                             max_new_tokens=64, \n",
    "                             top_k=0, \n",
    "                             top_p=0.95, \n",
    "                             num_return_sequences=1)\n",
    "\n",
    "    for i, sample_output in enumerate(outputs):\n",
    "        pred_text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "        pred_texts.append(pred_text)\n",
    "        label_texts.append(label_text)\n",
    "    # break\n",
    "result = rouge.compute(predictions=pred_texts, references=label_texts, \n",
    "                       use_stemmer=True)\n",
    "results.append(result)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e906f8c",
   "metadata": {},
   "source": [
    "### Prediction for sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "metrics = []\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    print(idx)\n",
    "    input_text = row['top_k']\n",
    "    gt_text = row['explanation']\n",
    "    \n",
    "    batch = tokenizer(input_text, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "    translated = model.generate(**batch)\n",
    "    pred_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    \n",
    "    preds.append(pred_text[0])\n",
    "    labels.append(gt_text)\n",
    "    \n",
    "metrics = rouge.compute(predictions=preds, references=labels, use_stemmer=True)    \n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3650441",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "label = \"California's largest electricity provider has turned off power to hundreds of thousands of customers.\"\n",
    "preds = tgt_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ef310",
   "metadata": {},
   "source": [
    "### Analyze manual scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe42639",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv('/Users/neeteshtiwari/Documents/PredictedExplanations_Scored_NG.csv')\n",
    "scores.groupby('Best explanation').agg({'Best explanation Rating': ['count', 'mean']\n",
    "                                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
